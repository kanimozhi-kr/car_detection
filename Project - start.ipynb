{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "120255aa-340d-49d9-a510-0e21fc1ceeec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls /Workspace/Users/kanikr1810@gmail.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e5103b3-964e-46db-8c78-9721055855f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e967a44-e422-4314-abc0-93c905be9774",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install Libraries in Serverless Mode"
    }
   },
   "outputs": [],
   "source": [
    "%pip install torch torchvision transformers opencv-python streamlit pillow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61aab0e1-79ce-43e3-89da-1fc9b735d76d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Restart the Python kernel"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9ab2926-6246-429d-bdf4-1b1c228a72ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e8af2b7-cd9e-4e26-961b-fc7a918f0560",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Verify Installation"
    }
   },
   "outputs": [],
   "source": [
    "%pip show torch torchvision streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2680a675-b092-4930-92dc-fdfa203bca2d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Kaggle Dataset"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be065858-3bc0-4f06-9f81-4d37d14f882a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cb55f91-4cb4-4c7b-b4b3-611162c0ae7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "!mkdir -p /tmp/.kaggle\n",
    "with open('/tmp/.kaggle/kaggle.json', 'w') as f:\n",
    "    f.write('{\"username\":\"kanimozhikr\",\"key\":\"b55c134d870dc6150c8f21e49f30fb35\"}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae7b0c66-b9b5-4bba-b4be-2001a72b6aca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "!kaggle datasets download -d anujms/car-damage-detection -p /tmp/\n",
    "!unzip /tmp/car-damage-detection.zip -d /Workspace/Users/kanikr1810@gmail.com/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a84d607-d56c-4e2d-9396-963c147a54dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!ls /Workspace/Users/kanikr1810@gmail.com/data1a/training/00-damage/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2fa5ac4-e0df-4b1a-8365-1af51fd75e20",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "data preprocessing"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Path to dataset\n",
    "data_dir = \"/Workspace/Users/kanikr1810@gmail.com/data1a/\"\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}, Test samples: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a60caeb1-d901-4f3e-99fe-fba06697b0cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c417cb2b-6f3a-4c21-9fa9-ae2426df6a6c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Training"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision import transforms\n",
    "\n",
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load pretrained ResNet50 for fraud detection\n",
    "fraud_model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "for param in fraud_model.parameters():\n",
    "    param.requires_grad = False\n",
    "fraud_model.fc = nn.Linear(fraud_model.fc.in_features, 3)\n",
    "fraud_model = fraud_model.to(device)\n",
    "\n",
    "# Define loss and optimizer for fraud model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(fraud_model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop for fraud detection\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    fraud_model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = fraud_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Validation for fraud detection\n",
    "fraud_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = fraud_model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Validation Accuracy (Fraud): {100 * correct / total:.2f}%\")\n",
    "\n",
    "# Save the trained fraud model\n",
    "torch.save(fraud_model.state_dict(), \"/Workspace/Users/kanikr1810@gmail.com/fraud_detector.pth\")\n",
    "print(\"Fraud model saved at /Workspace/Users/kanikr1810@gmail.com/\")\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Validation Accuracy (Fraud): {100 * correct / total:.2f}%\")\n",
    "\n",
    "# Example: Car detection on validation set\n",
    "car_model.eval()\n",
    "car_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "car_correct = 0\n",
    "car_total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        # Assuming car labels: 1 for car, 0 for not car (update as per your dataset)\n",
    "        outputs = car_model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        car_total += labels.size(0)\n",
    "        # If your dataset has car/not car labels, update this comparison\n",
    "        car_correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Validation Accuracy (Car Detection): {100 * car_correct / car_total:.2f}%\")\n",
    "\n",
    "# Save the trained fraud model\n",
    "torch.save(fraud_model.state_dict(), \"/Workspace/Users/kanikr1810@gmail.com/fraud_detector.pth\")\n",
    "print(\"Fraud model saved at /Workspace/Users/kanikr1810@gmail.com/\")\n",
    "\n",
    "# Save the car detection model (if fine-tuned)\n",
    "torch.save(car_model.state_dict(), \"/Workspace/Users/kanikr1810@gmail.com/car_detector.pth\")\n",
    "print(\"Car detector model saved at /Workspace/Users/kanikr1810@gmail.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca9a2609-e0f4-4a59-a5bc-9f29244e376a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%sh\n",
    "cp /Workspace/Users/kanikr1810@gmail.com/fraud_detector.pth ./fraud_detector.pth\n",
    "\n",
    "%sh\n",
    "cp /Workspace/Users/kanikr1810@gmail.com/car_detector.pth ./car_detector.pth\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6af2c787-c2bf-4cf3-ac38-02c4ba0afdf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install streamlit pyngrok torch torchvision pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ad50189-96d8-4e8f-b29d-3c4f0964ebc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e81fc40-ccc6-4c32-bc3c-329bf0e417ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4485b993-f72e-4a39-a8df-34da907d25ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load model architecture as in cell 12\n",
    "class FraudDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FraudDetector, self).__init__()\n",
    "        self.model = resnet50()\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, 3)  # 3 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Load trained weights\n",
    "model_path = \"./fraud_detector.pth\"\n",
    "model = FraudDetector()\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"Car Insurance Fraud Detection\")\n",
    "uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "\n",
    "if uploaded_file:\n",
    "    image = Image.open(uploaded_file).convert(\"RGB\")\n",
    "    st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    img_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "        pred_idx = torch.argmax(probs, dim=1).item()\n",
    "        # Map indices to class names (update as per your dataset)\n",
    "        class_names = [\"Genuine\", \"Minor Fraud\", \"Major Fraud\"]\n",
    "        label = class_names[pred_idx]\n",
    "        st.success(f\"Prediction: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c09e190-3a81-4bae-a1a7-cc804be7095c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%sh\n",
    "cp /tmp/fraud_detector.pth ./fraud_detector.pth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b014f51d-2ac1-47b0-9f67-e2b31c653437",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import base64\n",
    "\n",
    "file_path = \"/tmp/fraud_detector.pth\"  # Change if needed\n",
    "with open(file_path, \"rb\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "b64 = base64.b64encode(data).decode()\n",
    "download_link = f\"data:application/octet-stream;base64,{b64}Click here to download fraud_detector.pth</a>\"\n",
    "displayHTML(download_link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "445e000b-6de2-4eba-a0d8-217242531d47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Paths\n",
    "data_dir = \"/Workspace/Users/kanikr1810@gmail.com/data1a/\"\n",
    "save_dir = \"/Workspace/Users/kanikr1810@gmail.com/models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Transforms\n",
    "img_size = 224\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.1, hue=0.02),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Datasets (use same folder structure: root/class_name/*.jpg)\n",
    "full_dataset = datasets.ImageFolder(root=data_dir, transform=train_transform)\n",
    "\n",
    "# Split sizes\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.2 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "\n",
    "# Split with fixed seed\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size], generator=generator)\n",
    "\n",
    "# For val/test, override transform to deterministic\n",
    "val_dataset.dataset.transform = eval_transform\n",
    "test_dataset.dataset.transform = eval_transform\n",
    "\n",
    "# Dataloaders\n",
    "batch_size = 32\n",
    "num_workers = 4  # tweak per cluster\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "class_names = full_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(f\"Classes ({num_classes}): {class_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aebacf66-d46a-4e5a-b143-ed305f99dcb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "# Paths\n",
    "data_dir = \"/Workspace/Users/kanikr1810@gmail.com/data1a/\"\n",
    "save_dir = \"/Workspace/Users/kanikr1810@gmail.com/models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Transforms\n",
    "img_size = 224\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.1, hue=0.02),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Datasets (folder structure: root/class_name/*.jpg)\n",
    "full_dataset = datasets.ImageFolder(root=data_dir, transform=train_transform)\n",
    "class_names = full_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(f\"Classes ({num_classes}): {class_names}\")\n",
    "\n",
    "# Split sizes\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.2 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size], generator=generator)\n",
    "val_dataset.dataset.transform = eval_transform\n",
    "test_dataset.dataset.transform = eval_transform\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 0  # Use single-process data loading\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "# Model: ResNet50 for 3 classes [\"not_car\", \"ai_generated_car\", \"ai_edited_car\"]\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    train_acc = correct / total\n",
    "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "    val_acc = val_correct / val_total\n",
    "    print(f\"Epoch {epoch+1}: Train Acc {train_acc:.3f}, Val Acc {val_acc:.3f}\")\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), os.path.join(save_dir, \"car_type_detector_resnet50.pth\"))\n",
    "print(f\"Model saved at {save_dir}/car_type_detector_resnet50.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "053d48cd-be30-4b01-b873-f0a31bf4cf56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%pip install transformers streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c07c7411-b73b-4991-82aa-01e6781b8668",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "# Class names\n",
    "class_names = [\"not_car\", \"ai_generated_car\", \"ai_edited_car\"]\n",
    "\n",
    "# Model definition: ResNet50\n",
    "class CarTypeDetector(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(CarTypeDetector, self).__init__()\n",
    "        self.model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Load ResNet50 model\n",
    "resnet_model_path = \"./car_type_detector_resnet50.pth\"\n",
    "resnet_model = CarTypeDetector(num_classes=len(class_names))\n",
    "resnet_model.load_state_dict(torch.load(resnet_model_path, map_location=torch.device('cpu')))\n",
    "resnet_model.eval()\n",
    "\n",
    "# Load OpenAI CLIP model\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "\n",
    "# Image transform for ResNet\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"Car Type Detection: Not Car / AI Generated / AI Edited\")\n",
    "uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "\n",
    "if uploaded_file:\n",
    "    image = Image.open(uploaded_file).convert(\"RGB\")\n",
    "    st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
    "\n",
    "    # ResNet50 prediction\n",
    "    img_tensor = transform(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        output = resnet_model(img_tensor)\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "        pred_idx = torch.argmax(probs, dim=1).item()\n",
    "        label = class_names[pred_idx]\n",
    "        st.success(f\"ResNet50 Prediction: {label}\")\n",
    "        st.write(f\"ResNet50 Probabilities: {dict(zip(class_names, probs.squeeze().tolist()))}\")\n",
    "\n",
    "    # CLIP prediction\n",
    "    clip_inputs = clip_processor(\n",
    "        text=class_names,\n",
    "        images=image,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        clip_outputs = clip_model(**clip_inputs)\n",
    "        logits_per_image = clip_outputs.logits_per_image\n",
    "        clip_probs = logits_per_image.softmax(dim=1).squeeze().tolist()\n",
    "        clip_pred_idx = logits_per_image.argmax(dim=1).item()\n",
    "        clip_label = class_names[clip_pred_idx]\n",
    "        st.success(f\"CLIP Prediction: {clip_label}\")\n",
    "        st.write(f\"CLIP Probabilities: {dict(zip(class_names, clip_probs))}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7911700696398601,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Project - start",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
